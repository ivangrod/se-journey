[
{
	"uri": "https://ivangrod.github.io/se-journey/software-design/",
	"title": "Software Design",
	"tags": [],
	"description": "",
	"content": "Software Design "
},
{
	"uri": "https://ivangrod.github.io/se-journey/software-design/solid/",
	"title": "SOLID Principles",
	"tags": [],
	"description": "",
	"content": "SRP - Single responsibility principle Concepto:\n Una clase = Un concepto y responsabilidad Una clase debería tener sólo 1 razón para cambiar  Cómo conseguirlo:\n Clases pequeñas con objetivos acotados  [Code Smell] En clases de servicio, si presentan más de un método público, se interpreta que tienen más de una responsabilidad (hacen más de una cosa) [Code Smell] Nombres de clases abstractos, ej. EmailSender (1) vs EmailService (1..n). La terminología más específica no abre la puerta a añadir más funcionalidades    Finalidad:\n Alta cohesión y robustez Permitir composición de clases (inyectar colaboradores) Evitar duplicidad de código  Modelo de dominio Book:\nfinal class Book { public String getTitle() { return \u0026#34;A great book\u0026#34;; } public String getAuthor() { return \u0026#34;John Doe\u0026#34;; } public void printCurrentPage() { System.out.println(\u0026#34;current page content\u0026#34;); } } Servicio cliente del modelo de dominio:\nfinal class Client { public Client() { Book book = new Book(…); book.printCurrentPage(); } } Motivo del por qué no respetamos SRP: Book está acoplada al canal estándar de salida al imprimir la página actual. Sabe cómo modelar los datos y cómo imprimirlos.\nfinal class Book { public String getTitle() { return \u0026#34;A great book\u0026#34;; } public String getAuthor() { return \u0026#34;John Doe\u0026#34;; } public String getCurrentPage() { return \u0026#34;current page content\u0026#34;; } } final class StandardOutputPrinter { public void printPage(String page) { System.out.println(page); } } final class Client { public Client() { Book book = new Book(…); String currentPage = book.getCurrentPage(); StandardOutputPrinter printer = new StandardOutputPrinter(); printer.printPage(currentPage); } } Aplicando modularidad\ninterface Printer { public void printPage(String page); } final class StandardOutputPrinter implements Printer { public void printPage(String page) { System.out.println(page); } } final class StandardOutputHtmlPrinter implements Printer { public void printPage(String page) { System.out.println(\u0026#34;\u0026lt;div\u0026gt;\u0026#34; + page + \u0026#34;\u0026lt;/div\u0026gt;\u0026#34;); } }  Modelo de dominio anémico \u0026lt;-\u0026gt; DTOs\n OCP - Open/closed principle Concepto:\n El software debería estar abierto a extensión y cerrado a modificación. Ésto aplica tanto a nuestras clases internas, servicios, microservicios, casos de usos, etc.  Cómo conseguirlo:\n Evitando depender de implementaciones específicas, haciendo uso de clases abstractas o interfaces.  Finalidad:\n Facilidad para añadir nuevos Casos de uso en nuestra aplicación.  Violación OCP final class Song { private Double totalLength; private Double sentLength; public Double getSentLengthPercentage() { return sentLength * 100 / totalLength; } } final class File { private Double totalLength; private Double sentLength; public Double getSentLengthPercentage() { return sentLength * 100 / totalLength; } } OCP - Interface interface Measurable { public Double getTotalLength(); public Double getSentLength(); } final class Song implements Measurable { private Double totalLength; private Double sentLength; @Override public Double getTotalLength() { return totalLength; } @Override public Double getSentLength() { return sentLength; } } Clase Progress acoplada únicamente a la interface\nfinal class Progress { public Double getSentLengthPercentage(Measurable measurable) { return measurable.getSentLength() * 100 / measurable.getTotalLength(); } } OCP - Abstract class abstract class Measurable { abstract Double getTotalLength(); abstract Double getSentLength(); public Double getSentLengthPercentage() { return getSentLength() * 100 / getTotalLength(); } } final class Song extends Measurable { @Override public Double getTotalLength() { // ...  } @Override public Double getSentLength() { // ...  } } final class Progress { public Double getSentLengthPercentage(Measurable measurable) { // Nos llevamos lógica a nuestro modelo de dominio  return measurable.getSentLengthPercentage(); } } Interface - Abstract class   Beneficios de Interface - Usar para desacoplar entre capas:\n No modifica el árbol de jerarquía Permite implementar N Interfaces    Beneficios de Abstract Class - Determinados casos para Modelos de dominios:\n Permite desarrollar el patrón Template Method empujando la lógica al modelo  Problema: Dificultad de trazar   Getters privados (Tell don’t ask)    LSP - Liskov substitution principle Concepto:\n Si S es un subtipo de T, instancias de T deberían poderse sustituir por instancias de S sin alterar las propiedades del programa Es decir, al tener una jerarquía nos supone que estamos estableciendo un contrato en el padre, por lo que, garantizar que se mantiene dicho contrato en el hijo, nos permitirá que podamos sustituir al padre y la aplicación seguirá funcionando perfectamente.  Cómo:\n El comportamiento de las subclases debe respetar el contrato establecido en la superclase.  Finalidad:\n Mantener correctitud funcional para poder aplicar OCP  final class UserRepositoryMySql extends Repository implements UserRepository { public function save(User $user): void{ $this-\u0026gt;entityManager()-\u0026gt;persist($user); } public function flush(User $user) { $this-\u0026gt;entityManager()-\u0026gt;flush($user); } public function saveAll(Users $users) { each($this-\u0026gt;persister(),$users); } } Nuestra UserRepositoryMySql es una implementación de un repositorio MySql, pero ojo! con la característica de utilizar Doctrine como ORM. Doctrine implementa el Unit of work pattern, que nos ofrece algunas características:\n Utiliza una \u0026lsquo;caché\u0026rsquo; en memoria (unit of work) donde almacena inicialmente los datos antes de persistir en BD, haciendo más rápida su recuperación durante ese proceso. Cuando editamos estos objetos, compara las diferencias con el estado almacenado para saber él mismo qué atributos deben actualizarse.  Violación del LSP Como clientes externos que sólo conocemos la interface publicada, podríamos esperar que cuando se llamase al método save, con nuestra implementación se persistieran la información en BD.\ninterface UserRepository { public function save(User $user): void; public function saveAll(Users $users): void; public function search(UserId $id): ?User; public function all(): Users; } Sin embargo nuestra implementación del método save internamente llama a persist, que simplemente almacenará los datos en la unit of work sin forzar la persistencia real en BD. Como vemos, aunque se ha mantenido la firma de los métodos definidos en la interface, estaríamos violando el LSP puesto que no podríamos utilizarla para reemplazar otras implementaciones que no utilizan el Unit of work pattern y si estarían persistiendo en su BD al llamar al método save.\nISP - Interface segregation principle DIP - Dependency inversion principle "
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/aws/elb/",
	"title": "AWS - ELB",
	"tags": [],
	"description": "",
	"content": "Load balancers are servers that forward internet traffic to multiple servers (EC2 Instances) downstream.\n Spread load across multiple downstream instances Expose a single point of access (DNS) to your application. Seamlessly handle failures of downstream instances through health checks Do regular health checks to your instances. Provide SSL termination (HTTPS) or HTTPS security, for your website directly on load balancer site, Enforce stickiness with cookies. High availability across availability zones. Separate public traffic from private traffic  ELB (EC2 Load Balancer) Types of load balancer on AWS\n Classic Load Balancer (v1 - old generation) -\u0026gt; HTTP, HTTPS TCP Application Load Balancer (v2 - new generation) -\u0026gt; HTTP (HTTP2), HTTPS, Websocket Network Load Balancer (v2 - new generation) -\u0026gt; TCP, TLS, UDP  Application Load Balancer ++ Routing\n Routing tables to different target groups  Based on path in URL Based on hostname in URL Based on Query String, Headers     ALB are great fit for microservices \u0026amp; container-based application\n Target Groups\n EC2 instances - HTTP ECS tasks - HTTP Lambda functions - HTTP request is translated into a JSON event IP Addresses - private IPs  GTK (Good to Know)\n Fixed hostname with your Application Balancer The application servers don\u0026rsquo;t see the IP of the client directly.  The true IP of the client is going to be inserted in the header called X-Forwarded-For. You can also get the Port using X-Forwarded-Port and the protocol being used using X-Forwarded-Proto.    Load Balancer Stickiness Stickiness -\u0026gt; The same client will always be directed to the same underlying instance that is behind the load balancer. Classic Load Balancer and Application Load Balancer.\nThe cookie used for stickiness has an expiration date you control.\n Use Case: Make sure the user doesn\u0026rsquo;t lose his session data\n ¡¡¡ Enabling stickiness may bring imbalance to the load over the backend EC2 instance.\nCross-Zone Load Balancing When cross-zone balancing is enabled, that means that each load balancer instance will evenly distribute the traffic across all the instances in all AZ.\nSSL Certificates  Traffic between your clients and your load balancer to be encrypted in transit (in-flight encryption)   TLS (Transport Layer Security) \u0026gt; SSL (Secure Socket Layer)\n  The load balancer uses an X.509 certificate (SSL/TLS certificate) ACM (AWS Certificate Manager) SNI (Server Name Indication). It solves a very important problem, which is how do you load multiple SSL certificates onto one web server, in order for that web server to serve multiple websites.  Connection Draining  Time to complete \u0026ldquo;in-flight requests\u0026rdquo; while the instance is de-registering or unhealthy Stops sending new requests to the instance which is de-registering  :) Set a low value if your request are short (300 seconds by default)\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/aws/",
	"title": "AWS",
	"tags": [],
	"description": "",
	"content": "AWS  AWS - ELB   AWS - EC2   AWS - Security   AWS - Ops   AWS - Infrastructure   "
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/aws/ec2/",
	"title": "AWS - EC2",
	"tags": [],
	"description": "",
	"content": " Launch virtual machines on the cloud Storing data on virtual devices (EBS) Distributing load across machines (ELB) Scaling the services using an auto-scaling group (ASG)   AMI: Amazon Machine Image. An image to use to create our instances. They\u0026rsquo;re built for a specific AWS region.\n EC2 User Data AWS comnes with base images which can be customized using EC2 User Data:\nBootstrapping in an EC2 instance with EC2 user data script. Only run once \u0026lt;-\u0026gt; First start.\nIt\u0026rsquo;s used to automated boot tasks:\n Installing updates Installing software Downloading common files  EC2 Instance Launch Types  On Demand: Short workloads. Pay for what you use.  Recommend for short-term and un-interrupted workloads, where you can\u0026rsquo;t predict how the application will behave.\n Reserved: Long workloads (\u0026gt;= 1 year). Pay upfront for what you use with long term commitment  Recommend if you have a database and you know it\u0026rsquo;s going to be steady for a year or three years\n  Convertible reserved: Long workloads with flexible instances. Insecure about needing a C4, C4 large\n  Scheduled reserved: Reserve capacity, but only for a small window.\n  Spot: Short workloads. Very cheap. Loose instances.\n  Recommend for batch jobs, Big data analysis or workloads that are resilient to failures.\n Dedicated: No other customer will share our underlying hardware. Visibility into the underlying sockets / physical cores of the hardware. Dedicated Hosts: Book the entire physical server  https://www.ec2instances.info/ There are five distints characteristics:\n RAM (type, amount, generation) CPU (type, frequency, generation, number of cores) I/O (disk performance, ESB optimisations) Network (network bandwidth, network latency) GPU (Graphical Processing Unit)   T2/T3 are burstable instances. Can be amazing to handl unexpected traffic and getting the insurance that it will be handled correctly.\n "
},
{
	"uri": "https://ivangrod.github.io/se-journey/testing/tdd/tdd-schools/",
	"title": "TDD Schools",
	"tags": [],
	"description": "",
	"content": "Inside-out (Classic school) - Algorithms Enfocada en la verificación del estado de los objetos, siendo por ello imprescindible que el contexto de los test siempre deba estar formado por \u0026ldquo;objetos reales\u0026rdquo;, configurados previamente.\nPatterns: Mother Objects, Factory\nApproach:\nWe generalise the solution one failing test at a time so we end up with a simple, elegant solution that satisfies all of the tests up to that point. Based on triangulation\nOutside-in (London school) - Interactions Enfocada en verificar que el comportamiento de los objetos es el esperado. Verificar las correctas interacciones entre objetos, y no el estado en sí mismo de los objetos.\nFocusing on roles, responsibilities and interactions, as opposed to algorithms. It\u0026rsquo;s born out of the furnace of component-based, distributed and service-oriented applications\nPatterns: Test Double\nApproach:\nIdentify the roles, responsibilities and key interactions/collaborations between roles in an end-to-end implementation of the solution to satisfy a system-level scenario or acceptance test. Implement the code needed in each collaborator, one at a time, faking it\u0026rsquo;s direct collaborators and then work your way down through the \u0026ldquo;call stack\u0026rdquo; of interactions until you have a working end-to-end implementation that passes the front-end test.\nDemo Outside-in TDD https://www.youtube.com/watch?v=XHnuMjah6ps\nhttps://www.youtube.com/watch?v=gs0rqDdz3ko\nhttps://www.youtube.com/watch?v=R9OAt9AOrzI\nNotes\n  Use verify().methodXXX -\u0026gt; Test over commands method (void)\n  For command methods you need to test the side effects. After you identify the trigger for them.\n  You can\u0026rsquo;t test what you can\u0026rsquo;t control it\n  class Clock{ public String todayAsString(){ LocalDate today = today(); return today.format(DateTimeFormatter.ofPattern(\u0026#34;dd/MM/yyyy\u0026#34;)); } // Extract the randomness  protected LocalDate today(){ return LocalDate.now(); } } class ClockShould{ @Test public void return_todays_date_in_dd_MM_yyyy_format(){ Clock clock = new TesteableClock(); ... } private class TesteableClock extends Clock{ // Override and control the behaviour of the randomness  @Override protected LocalDate today(){ return LocalDate.of(2020,3,04); } } } "
},
{
	"uri": "https://ivangrod.github.io/se-journey/agile/",
	"title": "Agile",
	"tags": [],
	"description": "",
	"content": "Agile "
},
{
	"uri": "https://ivangrod.github.io/se-journey/agile/user-story/",
	"title": "User Story",
	"tags": [],
	"description": "",
	"content": "A user story describes functionality that will be valuable to either a user or purchaser of a system or software.\n CARD: A written description of the story used for planning and as a reminder CONVERSATION (++): About the story that serve to flesh out the details of the story CONFIRMATION: Tests that convey and document details and that can be used to determine when a story is complete. Acceptance test   Size: Stories that can be coded and tested between half a day and perhaps two weeks by one or a pair of programmers\n Epic When a story is too large it is sometimes referred to as an epic.\nEpic \u0026ldquo;A user can search for a job\u0026rdquo;. Split:\n A user can search for jobs by attributes like location, salary range, job title, company name, and the date the job was posted. A user can view information about each job that is matched by a search. (We don\u0026rsquo;t need to further divide it into more specific user stories) A user can view detailed information about a company that has posted a job.  Benefits\n User stories emphasize verbal rather than written communication. User stories are comprehensible by both you and the developers. User stories are the right size for planning. User stories work for iterative development. User stories encourage deferring detail until you have the best understanding you are going to have about what you really need.  Writing Stories (INVEST) Independent Avoid introducing dependencies between stories. Dependencies between stories lead to prioritization and planning problems.\nProblem\n A company can pay for a job posting with a Visa card. A company can pay for a job posting with a MasterCard. A company can pay for a job posting with an American Express card.  Estimating that it will take three days to support the first credit card type (regardless of which it is) and then one day each for the second and third.\nSolution\n Combine the dependent stories into one larger but independent story Find a different way of splitting the stories Putting two estimates on the card: one estimate if the story is done before the other story, a lower estimate if it is done after   A customer can pay with one type of credit card. A customer can pay with two additional types of credit cards.  Negotiable Details are negotiated -\u0026gt; Notes on the card help a developer and the customer to resume a conversation where it left off previously.\nRegardless of whether it is the same developer and customer who resume the conversation.\nProblem\nWhen as much detail is added can lead to the mistaken belief that the story cards reflect all the details and that there’s no further need to discuss the story with the customer.\nSolution\n  Story card as containing:\n phrase or two that act as reminders to hold the conversation notes about issues to be resolved during the conversation    Details that have already been determined through conversations become tests\n  Story card with few details. Discussion between customer and developer is somewhat abstract, Missing details or them to mistakenlyview their discussion as definitve or their estimate as accurate.\n  Valuable to users or customers Ex. stories valued by purchasers contemplating buying the product but would not be valued by actual users:\n Throughout the development process, the development team will produce documentation suitable for an ISO 9001 audit. The development team will produce the software in accordance with CMM Level 3. What you want to .  Problem\nAvoid stories that are only valued by developers\n All connections to the database are through a connection pool. All error handling and logging is done through a set of common classes.  Solution\n Up to fifty users should be able to use the application with a five-user database license. All errors are presented to the user and logged in a consistent manner.  Estimatable Problem\nThere are three common reasons why a story may not be estimatable:\n Developers lack domain knowledge. Developers lack technical knowledge. The story is too big.  Solution\n Developers should discuss it with the customer who wrote the story Spike: A brief experiment to learn about an area of the application. Developers learn just enough that they can estimate the task. Timebox: maximum amount of time.   Consider putting the spike in a different iteration\n Developers will need to disaggregate it into smaller, constituent stories.  Small Problem\nEpics typically fall into one of two categories:\n The compound story. An epic that comprises multiple shorter stories The complex story. An user story that is inherently large and cannot easily be disaggregated into a set of constituent stories.  Solution\n  How to split user stories   Story-Splitting-Flowchart.pdf  (744 ko)    Testable Stories must be written so as to be testable. Whenever possible, tests should be automated.\nProblem\nUntestable stories commonly show up for nonfunctional requirements, which are requirements about the software but not directly about its functionality.\n A user must find the software easy to use. A user must never have to wait long for any screen to appear.  Solution\n New screens appear within two seconds in 95% of all cases.  User Role Modeling A user role is a collection of defining attributes that characterize a population of users and their intended interactions with the system. There will be some overlap between different user roles.\nEx. Job Seeker, First Timer, Layoff Victim, Geographic Searcher, Monitor, Job Poster, Resume Reader\nBrainstorm an initial set of user roles Steps:\n The customer and as many of the developers as possible meet in a room. Start with everyone writing role names on cards The name of the new role and nothing more. No dicsussion. Continue until progress stalls and participants are having a hard time thinking up new roles.   A User Role is One User\n Organize the initial set Relationships between the roles.\nOverlapping roles are placed so that their cards overlap. If the roles overlap a little, overlap the cards a little. If the roles overlap entirely, overlap the cards entirely.\n System Roles -\u0026gt; If you think it will help, then identify an occasional non-human user role.\n  We don’t need user roles for every conceivable user of the system, but we need roles for the ones who can make or break the success of the project.\n Consolidate roles The authors of overlapping cards describe what they meant by those role names. After a brief discusson the group decides if the roles are equivalent.\n Job Poster | Resume Reader -\u0026gt; Recruiter Recruiter -\u0026gt; Internal Recruiter | External Recruiter. A generic role, is positioned above specialized versions of that role.  Refine the roles Model those roles by defining attributes of each role. A role attribute is a fact or bit of useful information about the users who fulfill the role. Any information about the user roles that distinguishes one role from another may be used as a role attribute.\n The frequency with which the user will use the software. The user’s level of expertise with the domain. The user’s general level of proficiency with computers and software. The user’s level of proficiency with the software being developed. The user’s general goal for using the software. Some users are after convenience, others favor a rich experience, and so on.  Extra Technique - Personas Creating a persona for the role. A persona is an imaginary representation of a user role. A persona should be described sufficiently that everyone on the team feels like they know the persona.\nFor example, Mario - Posting new job - may be described as follows:\nMario works as a recruiter in the Personnel department of SpeedyNetworks, a manufacturer of high-end networking components. He’s worked for SpeedyNetworks six years. Mario has a flex-time arrangement and works from home every Friday. Mario is very strong with computers and considers himself a power user of just about all the products he uses. Mario’s wife, Kim, is finishing her Ph.D. in chemistry at Stanford University. Because SpeedyNetworks has been growing almost consistently, Mario is always looking for good engineers.\n Think about writing a persona definition for one or two of the primary user roles.\n Extra Technique - Extreme Characters Use extreme characters when considering the design of a new system.\nFor example: PDA for a drug dealer, the Pope, and a twenty-year-old woman who is juggling multiple boyfriends.\nGathering Stories   X -\u0026gt; Get all of the user stories in one pass.\n  The relevance of a story changes based on the passage of time and on what stories were added to the product in prior iterations.\n   Write user stories that decrease in detail as the time horizon increases\n Having a rough idea of what a project will cost and what benefits it will deliver before getting funding and approval to start the project:\nUser interviews  Selection of interviewees. Real users whenever possible. Users who fill different user roles. Open-Ended and Context-Free questions, which are ones that do not include an implied answer or preference  Questionnaires  Information about stories you already have. Large user population  Information about how to prioritize the stories. Answers to specific questions.   It\u0026rsquo;s not recommend using questionnaires when trawling for stories  Observation  Observing users interact -\u0026gt; pick up insights. Rapid and direct feedback.  Release software as early and often as possible.    Story-Writing (++) Story-Writing Workshops\nUser Proxies They may not be users themselves but are on a project to help represent users.\n It is vital that a project include one or more real users on the customer team.\n The Users’ Manager  It is almost certain that the manager has different usage patterns of the software than does a typical user. Features which were of very minimal importance to the users they supervised, and developers can overemphasized in the product.  A Development Manager  The worst possible choices to act as a proxy user, unless perhaps you are writing software targeted at development managers. It is far too likely that she will also have some conflicting goals. If she is a development manager who does have domain expertise, then consider her a domain expert.  Salespersons  The election as an user proxy does not lead to a comprehensive view of the product to be built. The most important story to a salesperson will usually be the story whose absence cost her the last sale. Salespeople are, however, a great conduit to users and you should use them in this way.  Domain Experts  They are critical resources because of how well they understand the domain the software will be targeted at. Domain experts are ideal resources when building a domain model and identifying business rules, but workflow and usage issues are better derived from actual users. Problem -\u0026gt; you may end up with software aimed only at users with similar levels of domain expertise.  The Marketing Group  Marketing groups understand markets rather than users. Focus more on the quantity of features in the product than on the quality of those features. Relative priorities.  Former Users  She can be great as a proxy if her experience is very recent.  Customers  Customers are those who make the buying decision; they are not necessarily users of the software. It is important to consider the desires of your customers because they, not your users, are the ones who write the check to buy the software. (Unless, of course, your users and customers are the same people.)  Trainers and Technical Support  They spend their days talking to real users so they must certainly know what users want. :x: If you use a trainer as your user proxy, you will end up with a system that is easy to train. :x: If you use someone from technical support, you will end up with a system that is easily supported.  Business or Systems Analysts  Good as user proxies because they have one foot in the technology world and one foot in the domain of the software. :x: They prefer to think about a problem rather than research it. :x: Desire to spend too much time in the project’s upfront activities.   Avoid falling into the trap of thinking you know your user\u0026rsquo;s minds and do not need or can ignore your user proxy.\n Customer Team  Real user beats a proxy any time.\n The customer team should be constructed so that the strengths of one member balance the weaknesses of another member. Follow the next steps:\n Add real users. Different types of users, try to include a user of each type. Identify a single project champion or “first among equals” on the customer team. This project champion becomes responsible for coordinating customer team collaboration. Determine the factors critical to project success. Supplement the customer team with user proxies with the relevant knowledge, skills, and experience to address the project’s critical success factors.  Estimating Stories Story Points Each team defines them as they see fit:\n + An ideal day of work (that is, a day without any interruptions whatsoever—no meetings, no email, no phone calls, and so on).  It is easier than estimating in elapsed time Gives our estimates a slightly better foundation than when they are estimated in entirely nebulous units   An ideal week of work. Complexity of the story. \u0026hellip;   Joshua Kerievsky has suggested that story points represent Nebulous Units of Time, or NUTs\n Story estimates are owned by the team. A story comprises multiple tasks and that a task estimate is owned by the individual who will perform the task.\n Velocity. Number of story points a team completes (or expects to complete) in an iteration.\n Estimating Next, a estimation approach derived from the Wideband Delphi approach documented by Boehm:\n Gather together the customer and the developers who will participate in creating the estimates. Bring along the story cards and a stack of additional blank note cards The customer selects a story at random from the collection and reads it to the developers. (LOOP) Q/A. Not answer: take a guess / ask the team to defer estimating the story  When the programmers estimate a story, they should include everything they’ll need to do to complete the story: testing their code, talking to the customer, perhaps helping the customer plan or automate acceptance tests, and so on. (/LOOP) (LOOP)   Each developer writes an estimate on a card, not yet showing the estimate to the others The estimators turn over their cards or hold them up so everyone can see them. If estimates differ, the high and low estimators explain their estimates. At this point the group discusses it for up to a few minutes. (/LOOP)   The goal is for the estimators to converge on a single estimate that can be used for the story. It isn’t necessary that everyone in the room turn over a card with exactly the same estimate written down.\n Triangulation\nTriangulating an estimate refers to estimating a story based on its relationship to one or more other stories. Suppose a story is estimated at four story points and a second story is estimated at two story points:\n When the two stories are considered together the programmers should agree that the four-point story is roughly twice the size of the two-point story. Then, when they estimate a story as being three points, they should agree that it is roughly larger than the two-point story yet smaller than the four-point story.  Goal -\u0026gt; NOT altering the meaning of a story point.\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/testing/tdd/",
	"title": "Test-Driven Development",
	"tags": [],
	"description": "",
	"content": "Steps   Quickly add a test.\n  Run all tests and see the new one fail.\n  Make a little change.\n  Run all tests and see them all succeed.\n  Refactor to remove duplication.\nThe problem is the dependency between the code and the test—you can\u0026rsquo;t change one without changing the other. Our goal is to be able to write another test that “makes sense” to us, without having to change the code.\nIf dependency is the problem, duplication is the symptom.\nBy eliminating duplication before we go on to the next test, we maximize our chance of being able to get the next test running with one and only one change.\n  Points of interest  How each test can cover a small increment of functionality How small and ugly the changes can be to make the new tests run How often the tests are run How many teensy-weensy steps make up the refactorings  Beginning  We\u0026rsquo;ll make a to-do list to remind us what we need to do, to keep us focused and to tell us when we are finished.   We don\u0026rsquo;t start with objects, we start with tests.\n   Told a story with a snippet of code about how we wanted to view one operation\n  Ignored the details of JUnit for the moment\n  Made the test compile with stubs\n  Made the test run by committing horrible sins\n  Gradually generalized the working code, replacing constants with variables\n  Added items to our to-do list rather than addressing them all at once\n  TDD Patterns Three Laws of TDD   Law 1: You can’t write any production code until you have first written a failing spec.\n  Law 2: You can’t write more of a unit test than is sufficient to fail, and not compiling is failing.\n  Law 3: You can’t write more production code than is sufficient to pass the currently failing unit test.\n  Rule of Three Rule of three (\u0026ldquo;Three strikes and you refactor\u0026rdquo;) is a code refactoring rule of thumb to decide when similar pieces of code should be refactored to avoid duplication. It states that two instances of similar code don\u0026rsquo;t require refactoring, but when similar code is used three times, it should be extracted into a new procedure.\nTest-Driven Development Patterns TEST (NOUN) Positive feedback loop. The more stress you feel, the less testing you will do. The less testing you do, the more errors you will make. The more errors you make, the more stress you feel.\nISOLATED TEST  Make the tests so fast to run that you can run them myself, and run them often. That way you can catch errors before anyone else sees them\nA huge stack of errors didn\u0026rsquo;t usually mean a huge list of problems\n One convenient implication of isolated tests is that the tests are order independent.\nA second implication of isolated tests is that you have to work, sometimes work hard, to break your problem into little orthogonal dimensions\nTEST LIST TEST FIRST ASSERT FIRST  \u0026ldquo;What is the right answer?\u0026rdquo; || \u0026ldquo;How am I going to check?\u0026rdquo;\n TEST DATA  Use data that makes the tests easy to read and follow.\nDon\u0026rsquo;t have a list of ten items as the input data if a list of three items will lead you to the same design and implementation decisions.\n EVIDENT DATA Include expected and actual results in the test itself, and try to make their relationship apparent.\nRed Bar Patterns ONE STEP TEST Pick a test from the list that will teach you something and that you are confident you can implement. Each test should represent one step toward your overall goal.\nSTARTER TEST Start by testing a variant of an operation that doesn\u0026rsquo;t do anything.\n The first question you have to ask with a new operation is, \u0026ldquo;Where does it belong?\u0026rdquo; Until you\u0026rsquo;ve answered this question, you won\u0026rsquo;t know what to type for the test.\n If you write a realistic test first, then you will find yourself solving a bunch of problems at once. Beginning with a realistic test will leave you too long without feedback.\nEXPLANATION TEST Ask for and give explanations in terms of tests.\nA companion technique is to start giving explanations in terms of tests: \u0026ldquo;Here\u0026rsquo;s how it works now. When I have a Foo like this and a Bar like that, then the answer is 76. If I have a Foo like that and a Bar like this, though, I would like the answer to be 67.\u0026rdquo;\nLEARNING TEST When do you write tests for externally produced software? Before the first time you are going to use a new facility in the package.\nEx.: A project in which Learning Tests were routinely written. When new releases of the package arrived, first the tests were run (and fixed, if necessary). If the tests didn\u0026rsquo;t run, then there was no sense running the application because it certainly wouldn\u0026rsquo;t run.\nANOTHER TEST How do you keep a technical discussion from straying off topic? When a tangential idea arises, add a test to the list and go back to the topic.\nREGRESSION TEST When a defect is reported write the smallest possible test that fails and that, once run, will be repaired.\nRegression tests for the application give your users a chance to speak concretely to you about what is wrong and what they expect.\nBREAK  If you know what to type, type the Obvious Implementation. If you don\u0026rsquo;t know what to type, then Fake It. If the right design still isn\u0026rsquo;t clear, then Triangulate. If you still don\u0026rsquo;t know what to type, then you can take that shower.\n Testing Patterns CHILD TEST Write a smaller test case that represents the broken part of the bigger test case. Get the smaller test case running. Reintroduce the larger test case.\nMOCK OBJECT When you have an object that relies on an expensive or complicated resource, you must create a fake version of the resource that answers constants.\nSELF SHUNT For testing that one object communicates correctly with another, the best way is having the object under test communicate with the test case instead of with the object it expects.\n// TODO Review it\nLOG STRING Test that the sequence in which messages are called is correct -\u0026gt; Keep a log in a string, and append to the string when a message is called.\nLog Strings are particularly useful when you are implementing Observer and you expect notifications to come in a certain order.\nCRASH TEST DUMMY Test error code that is unlikely to be invoked -\u0026gt; Invoke it anyway with a special object that throws an exception instead of doing real work. Code that isn\u0026rsquo;t tested doesn\u0026rsquo;t work.\nprivate class FullFile extends File { public FullFile(String path) { super(path); } public boolean createNewFile() throws IOException { throw new IOException(); } } public void testFileSystemError() { File f = new FullFile(\u0026#34;foo\u0026#34;); try { saveAs(f); fail(); } catch (IOException e) {} } A Crash Test Dummy is like a Mock Object, except you don\u0026rsquo;t need to mock up the whole object. Java\u0026rsquo;s anonymous inner classes work well for sabotaging just the right method to simulate the error we want to exercise:\npublic void testFileSystemError() { File f= new File(\u0026#34;foo\u0026#34;) { public boolean createNewFile() throws IOException { throw new IOException(); } }; try { saveAs(f); fail(); } catch (IOException e) {} } BROKEN TEST Finish a solo session by writing a test case and running it to be sure it doesn\u0026rsquo;t pass. When you come back to the code, you then have an obvious place to start.\nYou have an obvious, concrete bookmark to help you remember what you were thinking.\nCLEAN CHECK-IN How do you leave a programming session when you\u0026rsquo;re programming in a team? Leave all of the tests running.\nYou need to start from a place of confidence and certainty.\nGreen Bar Patterns FAKE IT (\u0026lsquo;TIL YOU MAKE IT) Return a constant and gradually replace constants with variables until you have the real code. Remove duplication between the test and the production code.\n  Having a green bar feels completely different from having a red bar. When the bar is green, you know where you stand. You can refactor from there with confidence.\n  Starting with one concrete example and generalizing from there prevents you from prematurely confusing yourself with extraneous concerns.\n  TRIANGULATION We only generalize code (abstract) when we have two examples or more.\nWe briefly ignore the duplication between test and model code. When the second example demands a more general solution, then and only then do we generalize.\nOnce we have the two assertions and we have abstracted the correct implementation for plus, we can delete one of the assertions on the grounds that it is completely redundant with the other.\nOBVIOUS IMPLEMENTATION Type in the real implementation.\n Advice Commonly shift between two modes of implementation. When everything is going smoothly and you know what to type, you put in Obvious Implementation after Obvious Implementation (running the tests each time to ensure that what\u0026rsquo;s obvious to yours is still obvious to the computer). As soon as you get an unexpected red bar, you back up, shift to Faking implementations, and refactor to the right code. When you confidence returns, you go back to Obvious Implementations.\n ONE TO MANY An operation that works with collections of objects -\u0026gt; Implement it without the collections first, then make it work with collections.\nTPP - TRANSFORMATION PRIORITY PREMISE Cada nuevo test que convertimos a verde debe provocar una transformación en el código de producción que lo haga un poco más genérico de lo que era antes de añadir ese test. Secuencia de transformaciones propuesta por Robert C. Martin:\n {} –\u0026gt; nil: De no haber código a devolver nulo. nil -\u0026gt; constant: De nulo a devolver un valor literal. constant -\u0026gt; constant+: De un valor literal simple a uno más complejo. constant -\u0026gt; scalar: De un valor literal a una variable. statement -\u0026gt; statements: Añadir más líneas de código sin condicionales. unconditional -\u0026gt; if: Introducir un condicional scalar -\u0026gt; array: De variable simple a colección. array -\u0026gt; container: De colección a contenedor. statement -\u0026gt; recursion: Introducir recursión. if -\u0026gt; while: Convertir condicional en bucle. expression -\u0026gt; function: Reemplazar expresión con llamada a función. variable -\u0026gt; assignment: Mutar el valor de una variable.  xUnit Patterns ASSERTION Write boolean expressions that automate your judgment about whether the code worked.\n Si para validar un único comportamiento necesitamos varias líneas de asserts, a veces es mejor crear un método propio. Otra opción es implementar Custom Matchers\n Optional first parameter -\u0026gt; Add information about the assertion that will be printed if it ever fails. Some teams adopt the convention that all assertions must be accompanied by an informative error message.\nFIXTURE Cada test debería ser autosuficiente para crear el conjunto de datos que necesita. Estos datos son los fixtures.\nHow do you create common objects needed by several tests -\u0026gt; Convert the local variables in the tests into instance variables. Override setUp() and initialize those variables.\n  Test-fixture-creating code with the test -\u0026gt; Tests written with the setup code right there with the assertions are readable from top to bottom.\n  Test-fixture-creating code into a method called setUp() -\u0026gt; Set instance variables to the objects that will be used in the test. We would have to remember that the method was called, and remember what the objects looked like, before we could write the rest of the test.\n   In general, if I find myself wanting a slightly different fixture, then I start a new subclass of TestCase. @Before annotation may help us to evaluate the test class context.\n Fixture Setup Patterns\nEXTERNAL FIXTURE How do you release external resources in the fixture? Override tearDown() and release the resources.\nTEST METHOD Los nombres de los test deberían seguir siendo válidos cuando los pequeños detalles de implementación cambien. No deberían cambiar mientras que las reglas de negocio no cambien\nTip: Usar snake_case debido a que los nombres de los test tienden a ser muy largos. Al ser métodos que no van a ser invocados desde ninguna otra parte del código productivo, no supone problema que rompan la convención del lenguaje que se esté utilizando.\nEXCEPTION TEST How do you test for expected exceptions? Catch expected exceptions and ignore them, failing only if the exception isn\u0026rsquo;t thrown.\nTesting Exceptions (GitHub)\npublic void testMissingRate() { try { exchange.findRate(\u0026#34;USD\u0026#34;, \u0026#34;GBP\u0026#34;); fail(); /* Notice that we are careful only to catch the particular exception we expect, so we will also be notified if the wrong kind of exception is thrown */ } catch (IllegalArgumentException expected) {} } ALL TESTS How do you run all tests together? Make a suite of all the suites—one for each package, and one aggregating the package tests for the whole application.\nBest Practice Git   Para descartar los cambios locales en el paso green -\u0026gt; refactor basta con un git reset para volver al punto en el que los test pasan.\n  Commit en pequeños cambios incrementales. Para que nos formen parte del historial de Git, por algún motivo o por política de equipo, pueden unificarse con git squash\n  // TODO ¿Guía TDD con VCS?\nLegacy code Al no tener garantías de que el sistema se comporte como uno espera que lo haga, puede ser que plantear test partiendo de premisas incorrectas sea una pérdida de tiempo. Proceso para abordar ésto:\n Guardar cualquier cambio pendiente que tuvieras hasta ese momento (git commit) Añadir la nueva funcionalidad Ejecutar la aplicación a mano para validar que funciona como se espera Explorar la aplicación como tester/usuario para asegurar que ninguna otra funcionalidad está rota Añadir test automáticos que den cobertura a la nueva funcionalidad Verlos ejecutarse en verde Volver a dejar el código como estaba al principio (volviendo al commit anterior si es necesario) Lanzar de nuevo los test y verlos en rojo, confirmando que el error es el esperado Recuperar la última versión del código para ver los test en verde de nuevo  Exceptions Utilizar assert también para excepciones \u0026gt; código simétrico suele ser más fácil de entender :) :\n@Test public void should_fail_if_the_file_is_empty(){ assertThatExceptionOfType(IllegalFileException.class) .isThrownBy(() -\u0026gt; { filter.apply(emptyFile); }) } Sentencia declarativa: La expresión se evalúa de dentro hacia fuera. La función isThownBy nunca llegará a ejecutarse, porque el test se detendría antes con un rojo.\nTesting Exceptions (GitHub)\nPitfalls  Infravalorar el nombre de los test: Mayor entendimiento del problema y de la solución. Simplificar. Documentación viva y expresiva. Testar estructuras y asignaciones: Test demasiado acoplados a la implementación del código sin necesidad. No ayudan a implementar ninguna funcionalidad. Falta de refactoring en test: En un primer momento, no importa si el test tiene diez líneas. Cuando esté en verde, podremos mejorar la legilibilidad del test. Mocks return mocks: Tests que entorpecen, encarecen el mantenimiento. Pueden ser test de usar y tirar. Uso de variables estáticas/compartidas: Es recomendable lanzar baterías con las diferentes suites de test en paralelo en máquinasde varios núcleos. Ignorar test en rojo: No dejarlos ignorados más de un/dos días. Más de una regla por test: El test debe poner de manifiesto sólo una de las reglas de negocio. Cuando falle, tendremos mejor entendimiento de las consecuencias que puede acarrear. Introducir complejidad ciclomática: Cualquier cambio que añada indirección o cualquier otra posible complejidad en los test debe hacerse en la fase de refactor. Test parametrizados: Pocas veces es útil, ya que usando triangulación con dos o tres casos podríamos obtener el mismo resultado. Si fuera necesario, utilizar herramientas de test basados en propiedades. Forzar el diseño para poder probar: La interfaz publica de un módulo o de una clase es un compromiso adquirido con sus consumidores. Esperas aleatorias para resolver asincronía: Para que los test inspiren confianza tienen que ser deterministas y además rápidos en la ejecución. Dependencias de plataforma y de máquina. Ausencia de exploratory testing: Probar funcionalidades que no hemos probado nosotros. Exceso de test de la GUI: Tests que atacan a la interfaz gráfica son los más frágiles de todos. Cadenas de transiciones entre estados: Partir el test en varios, de forma que cada uno se limita a verificar una sola transición de estado. Quizás necesitemos alguna vía de configuración de partida. Ausencia de documentación.  "
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/aws/security/",
	"title": "AWS - Security",
	"tags": [],
	"description": "",
	"content": "IAM - Identity and Access Management. Global view (non-region)\nUser -\u0026gt; Usually a physical person Group -\u0026gt; Functions (admin, devops) / Teams (engineering, design) Role -\u0026gt; Internal usage within AWS resources\nPolicies -\u0026gt; Defines what each of the above can or can\u0026rsquo;t do. Permissions are governed by Policies. + Least Privilege principle\nSecurity Groups Network security in AWS. They control how traffic will be allowed into your EC2 Machines.\n  Access to ports\n  Authorised IP ranges - IPv4 and IPv6\n  Control of inbound network\n  Control of outbound network\n  Can be attached to multiple instances\n  Locked down to a region/VPC (Virtual Private Cloud) combination\n   It\u0026rsquo;s good to maintain one separate security group for SSH access\n Elastic IP  Stop -\u0026gt; Start an instance EC2 -\u0026gt; Change the public IP Elastic IP -\u0026gt; Fixed public IPv4   Avoid Elastic IP. Often reflect poor architectural decisions It\u0026rsquo;s better use a random public IP and register a DNS name to it It\u0026rsquo;s better use a Load Balancer and don\u0026rsquo;t use a public IP\n Load Balancer Security Groups  Load Balancer Security Group -\u0026gt; Source - 0.0.0.0/0 Allow HTTP from anywhere Application Security Group -\u0026gt; Source - sg-054b5ff5eaa02f2b6e Allow Traffic only from Load balancer  "
},
{
	"uri": "https://ivangrod.github.io/se-journey/testing/test-types/",
	"title": "Test Types",
	"tags": [],
	"description": "",
	"content": " Claros, concisos y certeros: Arrange - Act - Assert / Given - When - Then. Datos mínimos relevantes para entender y distinguir cada escenario. Feedback rápido e informativo Simplicidad: Dependencias - librerías, frameworks - ¿cuánto cuesta entender como funcionan todas estas piezas? Robustez: Cuando un test se rompe debería hacerlo por un solo motivo. Debería ser muy expresivo, señalando el motivo del fallo como para que no haga falta depurar el sistema. Flexibilidad: Refactoring Isolation: El resultado de un test no debería estar sujeto a la ejecución de otro test, deberían ser independientes a la hora de ejecutarse.  Unit Integration Acceptance Acceptance testing is the process of verifying that stories were developed such that each works exactly the way the customer team expected it to work. They represent the expectations of a project\u0026rsquo;s users.\nHaving basic criteria that tell us when something is done is the best way to avoid putting too much, or too little, time and effort into it.\n The acceptance tests need to be specified by the customer -\u0026gt; Minimally the customer needs to specify the tests that will be used to know when a story has been correctly developed.\n Write early More of the customer team’s assumptions and expectations are communicated earlier to the developers.\nTests should be written as early in an iteration as possible. Tests are generally written at the following times:\n Whenever the customer and developers talk about the story and want to capture explicit details As part of a dedicated effort at the start of an iteration but before programming begins Whenever new tests are discovered during or after the programming of the story  Questions from customer  What else do the programmers need to know about this story? What am I assuming about how this story will be implemented? Are there circumstances when this story may behave differently? What can go wrong during the story?  Example User story \u0026ldquo;A user can pay for the items in her shopping cart with a credit card\u0026rdquo;:\n Test with Visa, MasterCard and American Express (pass). Test with Diner’s Club (fail). Test with a Visa debit card (pass). Test with good, bad and missing card ID numbers from the back of the card. Test with expired cards. Test with different purchase amounts (including one over the card’s limit).  End to end  Comparación con unit test  + granularidad - velocidad + complejidad + fragilidad - acoplamiento a la implementación del sistema + requerimiento de infraestructura para poder ser inocuo + dependencia del entorno de ejecución del sistema    Mutation Consiste en introducir pequeños cambios en el código de producción a modo de defectos, por ejemplo, invertir una condición lógica, y forzar así un fallo en los tests.\nExploratory Explorar la aplicación para descubrir cómo romperla\n Pair testing: Explorar el software a pares. Si una de las personas tiene más habilidad explorando y la otra escribiendo test automáticos, pueden aprovechar para ir automatizando las pruebas que están sin cubrir. Mob testing: Explorar el software en grupo.  Property based Ejecutar miles de casos que ponen a prueba el código de forma que un humano escribiendo test automáticos no haría.\n// TODO Karumi -\u0026gt; MaxibonKata -\u0026gt; Java y JUnit-QuickCheck\nSnapshot Testing pyramid  Few e2e tests. A lot unit tests\n "
},
{
	"uri": "https://ivangrod.github.io/se-journey/culture/",
	"title": "Culture",
	"tags": [],
	"description": "",
	"content": "Culture "
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/aws/ops/",
	"title": "AWS - Ops",
	"tags": [],
	"description": "",
	"content": "Access Access: Configure Instance details \u0026gt; Advance details \u0026gt; User data\nAccess: SSH / EC2 Instace connect\nchmod 0400 udemy-instance-key.pem (restrict private key) SSH -\u0026gt; ssh -i udemy-instance-key.pem ec2-user@34.240.37.21\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/testing/double-patterns/",
	"title": "Double Patterns",
	"tags": [],
	"description": "",
	"content": "http://xunitpatterns.com/Test%20Double%20Patterns.html\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/aws/infrastructure/",
	"title": "AWS - Infrastructure",
	"tags": [],
	"description": "",
	"content": "AWS Regions Availability Zone (AZ) (us-east-1a, us-east-2)\nPhysical data center in the region. Isolated from others from disasters.\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/testing/testing-resources/",
	"title": "Testing Resources",
	"tags": [],
	"description": "",
	"content": "xUnit  xUnit Patterns  BDD  Example mapping  "
},
{
	"uri": "https://ivangrod.github.io/se-journey/testing/",
	"title": "Testing",
	"tags": [],
	"description": "",
	"content": "Testing "
},
{
	"uri": "https://ivangrod.github.io/se-journey/cloud/",
	"title": "Cloud",
	"tags": [],
	"description": "",
	"content": "Cloud "
},
{
	"uri": "https://ivangrod.github.io/se-journey/git/",
	"title": "Git",
	"tags": [],
	"description": "",
	"content": "Git "
},
{
	"uri": "https://ivangrod.github.io/se-journey/templates/",
	"title": "Templates",
	"tags": [],
	"description": "",
	"content": "Templates "
},
{
	"uri": "https://ivangrod.github.io/se-journey/glossary/",
	"title": "Glossary",
	"tags": [],
	"description": "",
	"content": "Glossary "
},
{
	"uri": "https://ivangrod.github.io/se-journey/glossary/terms/",
	"title": "Terms",
	"tags": [],
	"description": "",
	"content": " ACL -\u0026gt; Access Control Lists are network traffic filters that can control incoming or outgoing traffic. FIRST -\u0026gt; Testing context: Fast, Independent, Repeatable, Self-validated, Timely. YAGNI -\u0026gt; You ain\u0026rsquo;t gonna need it  "
},
{
	"uri": "https://ivangrod.github.io/se-journey/",
	"title": "Software Engineer Journey",
	"tags": [],
	"description": "",
	"content": "Software Engineer Journey  Software Design   Agile   Culture   Testing   Cloud   Git   Templates   Glossary   "
},
{
	"uri": "https://ivangrod.github.io/se-journey/templates/issue/",
	"title": "Issue",
	"tags": [],
	"description": "",
	"content": "I\u0026rsquo;m submitting a \u0026hellip;  bug report feature request support request  What is the current behavior? …\nIf the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via https://plnkr.co or similar (you can use this template as a starting point: http://plnkr.co/edit/tpl:AvJOMERrnz94ekVua0u5).\nAny logs, error output, etc? (If it’s long, please paste to https://ghostbin.com/ and insert the link here.)\nWhat are the steps to reproduce this issue?  … … …  What is the expected behavior? …\nWhat is the motivation / use case for changing the behavior? Please tell us about your environment:  Version: 2.0.0-beta.X Browser: [all | Chrome XX | Firefox XX | IE XX | Safari XX | Mobile Chrome XX | Android X.X Web Browser | iOS XX Safari | iOS XX UIWebView | iOS XX WKWebView ] Operating System: Language: [all | TypeScript X.X | ES6/7 | ES5 | Dart] SDK Version  Other information Detailed explanation, stacktraces, related issues, suggestions how to fix, links for us to have context (eg. stackoverflow, gitter, etc)\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/templates/pull-request/",
	"title": "Pull Request",
	"tags": [],
	"description": "",
	"content": "Checklist\nPlease check if your PR fulfills the following requirements:\n Tests for the changes have been added (for bug fixes / features) Docs have been reviewed and added / updated if needed (for bug fixes / features) Build was run locally and any changes were pushed Lint has passed locally and any fixes were made for failures  Pull request type Please check the type of change your PR introduces:\n Bugfix Feature Code style update (formatting, renaming) Refactoring (no functional changes, no api changes) Build related changes Documentation content changes Other (please describe):  What is the current behavior? Issue Number: N/A\nWhat is the new behavior?  \u0026hellip; \u0026hellip; \u0026hellip;  Does this introduce a breaking change?  Yes No  If this introduces a breaking change, please describe the impact and migration path for existing applications below.\nOther information Any other information that is important to this PR such as screenshots of how the component looks before and after the change.\n"
},
{
	"uri": "https://ivangrod.github.io/se-journey/git/git-commit-message/",
	"title": "Git Commit Message",
	"tags": [],
	"description": "",
	"content": "Capitalized, short (50 chars or less) summary More detailed explanatory text, if necessary. Wrap it to about 72 characters or so. In some contexts, the first line is treated as the subject of an email and the rest of the text as the body. The blank line separating the summary from the body is critical (unless you omit the body entirely); tools like rebase can get confused if you run the two together. Write your commit message in the imperative: \u0026quot;Fix bug\u0026quot; and not \u0026quot;Fixed bug\u0026quot; or \u0026quot;Fixes bug.\u0026quot; This convention matches up with commit messages generated by commands like git merge and git revert. Further paragraphs come after blank lines. - Bullet points are okay, too - Typically a hyphen or asterisk is used for the bullet, followed by a single space, with blank lines in between, but conventions vary here - Use a hanging indent  git log \u0026ndash;pretty=oneline shows a terse history mapping containing the commit id and the summary git rebase \u0026ndash;interactive provides the summary for each commit in the editor it invokes If the config option merge.summary is set, the summaries from all merged commits will make their way into the merge commit message git shortlog uses summary lines in the changelog-like output it produces git format-patch, git send-email, and related tools use it as the subject for emails reflogs, a local history accessible with git reflog intended to help you recover from stupid mistakes, get a copy of the summary gitk has a column for the summary GitHub uses the summary in various places in their user interface  "
},
{
	"uri": "https://ivangrod.github.io/se-journey/culture/code-review/",
	"title": "Code Review",
	"tags": [],
	"description": "",
	"content": " Code review is a human communication process\n 3-steps process   The developer who wrote the code creates a pull request (PR) and lets the team know that the PR was created. (Slack bot)\n  Once the PR is created, someone else starts reviewing the code, in accordance with a guide providing rules, standards and processes.\n  After one or two developers have reviewed the code, one or both steps should be followed:\n The code needs improvement. Then, the developer could either start a discussion regarding the best way to solve the problem, or just follow the suggestions. This step is repeated until all developers are involved and agree on the fact that the code is good enough. The iterations stop and the code can be merged back into the development branch. If the code is good enough it can be merged into the development branch.    Guide For An Effective Code Review Code style guide (Severity = Low)  In may be used to limit method body length, cyclomatic complexity, usage of legacy methods and much more. All this while requiring the format of the code to be common.\nLinting and Code Style Check Leave static code analysis and coding style check to machines with tools like SonarQube and ESLint, and spare human eyes for important parts like business logics and algorithms.\nGoogle Java Style Guide\n https://github.com/google/google-java-format  Software Architecture (Severity = Medium)  Software architecture is the process of converting software characteristics such as flexibility, scalability, feasibility, reusability, and security into a structured solution that meets the technical and the business expectations.\nSoftware Design (SOLID) (Severity = Medium) Change Traceability  It is assumed that changes to the code are done based on specifications. These specs should be re-iterated very briefly in:\n Change log. // TODO Git commit messages. The user performing the changes must also be identifiable.   Git history shall be kept clean by properly rebasing feature branches before merging them back into the main development branch. // TODO Rebase feature branches.\n Documentation Coverage (Severity = Medium)  Documentation of the code is not to be a separate process, but rather be done together with the implementation.\n Focus also on the “why” and “how” not only on the “what”.\n Provide enough context for creating meaningful pull request  Issue template Pull request template  New Developer On-boarding  The review process provides an opportunity for mentorship and collaboration, and, minimally, diversifies the understanding of code in the code base.\nDependencies (Severity = Medium)  The security, licensing and versioning implications of 3rd party and open source solutions must be considered and monitored.\nAntipatterns (Severity = High) Maintainability (Severity = High)   Extending Testing Debugging Configuring Deploying Automating  May be scored based on the efforts needed for the application\nExtensibility (Severity = Medium) Legibility (Severity = High)  Legible code is more reusable, bug-free, and future-proof\nReusability (Severity = High)  Components used across the application(s) should be identified and modularised for better reusability and maintainability.\nSecurity (Severity = High)    OWASP Secure Code Review Guide   OWASP_Code_Review_Guide_v2.pdf  (2368 ko)    Performance (Severity = High)   Asynchronous Parallel execution Caching Appropriate usage of resources Memory leaks  Scaleability (Severity = High) Usability (Severity = Medium)  The interfaces for other services, applications or 3rd parties shall be well documented and follow standards in order to be usable.\nThe APIs should be implementable and testable solely using the documentation available without any dedicated support personnel.\nTesting Coverage (Severity = High) Automation Of Builds And Deployments Motivation   Committers are motivated Sharing knowledge  Scope and size (Severity = Medium)  Changes should have a narrow, well-defined, self-contained scope that they cover exhaustively.\nKeep changes small Treat each PR as a releasable unit (feature, bug fix) or a cohesive idea which is meaningful to the PR.\n Single-piece flow -\u0026gt; LEAN manufacturing\n If a CR makes substantive changes to more than ~5 files, or took longer than 1–2 days to write, or would take more than 20 minutes to review, consider splitting it into multiple self-contained CRs.\nReview often and shorten sessions Code reviews in reasonable quantity, at a slower pace, for a limited amount of time result in the most effective code review.\n 3PM code review rule -\u0026gt; Every day at 3PM is Code Review time. Improving burndown charts.\n Refactoring changes   Refactoring changes should not alter behavior\nA behavior-changing changes should avoid refactoring and code formatting changes.\n  Refactoring changes often touch many lines and files and will consequently be reviewed with less attention. Large refactoring changes break cherry-picking, rebasing, and other source control magic. Expensive human review time should be spent on the program logic rather than style, syntax, or formatting debates.  Measure the progress   If you can’t see it, you can’t measure it, you can’t improve it!\n  SonarQube project dashboard Team based code coverage PR Comment Notification PR size and resolution time. Making a releasable task/change small is a valid skill in DevOps. We try to promote this idea with the Resolution time vs. PR size chart  Checklist for Developers Implementation\n My code compiles I have considered proper use of exceptions I have made appropriate use of logging I have eliminated unused imports I have eliminated IDE warnings I have considered possible NPEs Was performance considered? Was security considered? Does the code release resources? (HTTP connections, DB connection, files, etc) Can any code be replaced by calls to external reusable components or library functions? Thread safety and possible deadlocks  Legibility and style\n My code is tidy (indentation, line length, no commented-out code, no spelling mistakes, etc) The code follows the coding standards  Maintainability\n My code includes javadoc where appropriate My code has been developer-tested and includes unit tests Are there any leftover stubs or test routines in the code? Are there any hardcoded, development only things still in the code? Corner cases well documented or any workaround for a known limitation of the frameworks  Checklist for Reviewers Purpose\n Does this code accomplish the author’s purpose? All functions and classes exist for a reason.  Implementation\n The functionality fits the current design/architecture Types have been generalized where possible Parameterized types have been used appropriately Frameworks have been used appropriately Does the change follow standard patterns? Do you see potential for useful abstractions? Command classes have been designed to undertake one task only The code does not use unjustifiable static methods/blocks Logging used appropriately (proper logging level and details) NPEs and AIOBs Exceptions have been used appropriately Does the change add compile-time or run-time dependencies (especially between sub-projects)? Potential threading issues have been eliminated where possible Any security concerns have been addressed Performance was considered  Legibility and style\n Repetitive code has been factored out The code complies to coding guidelines and code style Does this code have TODOs?. Have the author submit a ticket on GitHub Issues or JIRA and attach the issue number to the TODO.  Maintainability\n Comments are comprehensible Comments are neither too numerous nor verbose Unit tests are present and they covering interesting cases Does this code need integration tests? Does this CR introduce the risk of breaking test code, staging stacks, or integrations tests? Does this change break backward compatibility? Is it OK to merge the change at this point or should it be pushed into a later release? Was the external documentation updated?  Tips in Comments: concise, friendly, actionable  Written in neutral language Critique the code, not the author. Avoid possessive pronouns Avoid absolute judgements Try to differentiate between:  Suggestions (e.g., “Suggestion: extract method to improve legibility”) Required changes (e.g., “Add @Override”) Points that need discussion or clarification (e.g., “Is this really the correct behavior? If so, please add a comment explaining the logic.”)    Examples class MyClass { private int countTotalPageVisits; //R: name variables consistently  private int uniqueUsersCount; } interface MyInterface { /** Returns {@link Optional#empty} if s cannot be extracted. */ public Optional\u0026lt;String\u0026gt; extractString(String s); /** Returns null if {@code s} cannot be rewritten. */ //R: should harmonize return values: use Optional\u0026lt;\u0026gt; here, too  public String rewriteString(String s); } //R: remove and replace by Guava\u0026#39;s MapJoiner String joinAndConcatenate(Map\u0026lt;String, String\u0026gt; map, String keyValueSeparator, String keySeparator); int dayCount; //R: nit: I usually prefer numFoo over fooCount; up to you, but we should keep it consistent in this project //R: This performs numIterations+1 iterations, is that intentional? // If it is, consider changing the numIterations semantics? for (int i = 0; i \u0026lt;= numIterations; ++i) { ... } otherService.call(); //R: I think we should avoid the dependency on OtherService. Can we discuss this in person? "
},
{
	"uri": "https://ivangrod.github.io/se-journey/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ivangrod.github.io/se-journey/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]